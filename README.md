# DataScientest-Project
Final project for DataScientest training program


Detection of toxic comments using classification methods. The aim was to build a fast and efficient model that can detect if a comment is
nontoxic or toxic depending on its content.
Our project is inspired by a Kaggle project, so we based ourselves on their criteria to separate toxic and nontoxic comments 
for our training phase.
Detection of toxic comments: insulting, threatening, obscene ...

Modeling chosen: classification (such as feelings detection, moderation problem)

I also added my file which was used to create my application on a website. This application take in input a comment and give in output if this comment is toxic or not toxic

The goal of this application is to show my work in a simple way, even for non-initiate.

If you want to give it a look, it will be my pleasure -> https://polar-falls-57052.herokuapp.com/
